{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 第四章 基础实战——FashionMNIST时装分类","metadata":{}},{"cell_type":"markdown","source":"<img src=\"./fashion-mnist-sprite.png\" width=\"400\" />  \n  \n经过前面三章内容的学习，我们完成了以下的内容：  \n- 对PyTorch有了初步的认识\n- 学会了如何安装PyTorch以及对应的编程环境\n- 学习了PyTorch最核心的理论基础（张量&自动求导）\n- 梳理了利用PyTorch完成深度学习的主要步骤和对应实现方式  \n  \n现在，我们通过一个基础实战案例，将第一部分所涉及的PyTorch入门知识串起来，便于大家加深理解。同时为后续的进阶学习打好基础。 \n  \n我们这里的任务是对10个类别的“时装”图像进行分类，使用FashionMNIST数据集（https://www.kaggle.com/zalando-research/fashionmnist ）。上图给出了FashionMNIST中数据的若干样例图，其中每个小图对应一个样本。  \nFashionMNIST数据集中包含已经预先划分好的训练集和测试集，其中训练集共60,000张图像，测试集共10,000张图像。每张图像均为单通道黑白图像，大小为32\\*32pixel，分属10个类别。  \n  \n下面让我们一起将第三章各部分内容逐步实现，来跑完整个深度学习流程。","metadata":{}},{"cell_type":"markdown","source":"**首先导入必要的包**  ","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:40:57.481382Z","iopub.execute_input":"2022-05-17T13:40:57.482009Z","iopub.status.idle":"2022-05-17T13:40:57.489863Z","shell.execute_reply.started":"2022-05-17T13:40:57.481973Z","shell.execute_reply":"2022-05-17T13:40:57.488422Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"**配置训练环境和超参数**  \n","metadata":{}},{"cell_type":"code","source":"# 配置GPU，这里有两种方式\n## 方案一：使用os.environ\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\n# # 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可\n# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n\n## 配置其他超参数，如batch_size, num_workers, learning rate, 以及总的epochs\nbatch_size = 256\nnum_workers = 2   # 对于Windows用户，这里应设置为0，否则会出现多线程错误\nlr = 1e-4\nepochs = 20","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:40:57.493070Z","iopub.execute_input":"2022-05-17T13:40:57.493833Z","iopub.status.idle":"2022-05-17T13:40:57.504925Z","shell.execute_reply.started":"2022-05-17T13:40:57.493777Z","shell.execute_reply":"2022-05-17T13:40:57.503799Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"第一种方式更简单，后续使用时只需要xxx.cuda()\n第二种方式：xxx.to_device(device)","metadata":{}},{"cell_type":"markdown","source":"**数据读入和加载**  \n这里同时展示两种方式:  \n- 下载并使用PyTorch提供的内置数据集  \n- 从网站下载以csv格式存储的数据，读入并转成预期的格式    \n第一种数据读入方式只适用于常见的数据集，如MNIST，CIFAR10等，PyTorch官方提供了数据下载。这种方式往往适用于快速测试方法（比如测试下某个idea在MNIST数据集上是否有效）  \n第二种数据读入方式需要自己构建Dataset，这对于PyTorch应用于自己的工作中十分重要  \n  \n同时，还需要对数据进行必要的变换，比如说需要将图片统一为一致的大小，以便后续能够输入网络训练；需要将数据格式转为Tensor类，等等。\n  \n这些变换可以很方便地借助torchvision包来完成，这是PyTorch官方用于图像处理的工具库，上面提到的使用内置数据集的方式也要用到。PyTorch的一大方便之处就在于它是一整套“生态”，有着官方和第三方各个领域的支持。这些内容我们会在后续课程中详细介绍。","metadata":{}},{"cell_type":"code","source":"# 首先设置数据变换\nfrom torchvision import transforms\n\nimage_size = 28\ndata_transform = transforms.Compose([\n    transforms.ToPILImage(),   # 这一步取决于后续的数据读取方式，如果使用内置数据集则不需要\n    transforms.Resize(image_size),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:40:57.507844Z","iopub.execute_input":"2022-05-17T13:40:57.508768Z","iopub.status.idle":"2022-05-17T13:40:57.518132Z","shell.execute_reply.started":"2022-05-17T13:40:57.508725Z","shell.execute_reply":"2022-05-17T13:40:57.516903Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# ## 读取方式一：使用torchvision自带数据集，下载可能需要一段时间\n# from torchvision import datasets\n\n# train_data = datasets.FashionMNIST(root='./', train=True, download=True, transform=data_transform)\n# test_data = datasets.FashionMNIST(root='./', train=False, download=True, transform=data_transform)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-17T13:40:57.521760Z","iopub.execute_input":"2022-05-17T13:40:57.522579Z","iopub.status.idle":"2022-05-17T13:40:57.529725Z","shell.execute_reply.started":"2022-05-17T13:40:57.522494Z","shell.execute_reply":"2022-05-17T13:40:57.528522Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# train_data","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:40:57.531764Z","iopub.execute_input":"2022-05-17T13:40:57.532777Z","iopub.status.idle":"2022-05-17T13:40:57.544114Z","shell.execute_reply.started":"2022-05-17T13:40:57.532732Z","shell.execute_reply":"2022-05-17T13:40:57.543044Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"## 读取方式二：读入csv格式的数据，自行构建Dataset类\n# csv数据下载链接：https://www.kaggle.com/zalando-research/fashionmnist\nclass FMDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n        self.images = df.iloc[:,1:].values.astype(np.uint8)\n        self.labels = df.iloc[:, 0].values\n        \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        image = self.images[idx].reshape(28,28,1)\n        label = int(self.labels[idx])\n        if self.transform is not None:\n            image = self.transform(image)\n        else:\n            image = torch.tensor(image/255., dtype=torch.float)\n        label = torch.tensor(label, dtype=torch.long)\n        return image, label\n\ntrain_df = pd.read_csv(\"../input/newminist1/fashion-mnist_train.csv\")\ntest_df = pd.read_csv(\"../input/newminist/fashion-mnist_test.csv\")\ntrain_data = FMDataset(train_df, data_transform)\ntest_data = FMDataset(test_df, data_transform)\n\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-17T13:40:57.546339Z","iopub.execute_input":"2022-05-17T13:40:57.546875Z","iopub.status.idle":"2022-05-17T13:41:03.831483Z","shell.execute_reply.started":"2022-05-17T13:40:57.546833Z","shell.execute_reply":"2022-05-17T13:41:03.830447Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在构建训练和测试数据集完成后，需要定义DataLoader类，以便在训练和测试时加载数据  \n","metadata":{}},{"cell_type":"code","source":"#在构建训练和测试数据集完成后，需要定义DataLoader类，以便在训练和测试时加载数据\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:41:03.832992Z","iopub.execute_input":"2022-05-17T13:41:03.833325Z","iopub.status.idle":"2022-05-17T13:41:03.842448Z","shell.execute_reply.started":"2022-05-17T13:41:03.833286Z","shell.execute_reply":"2022-05-17T13:41:03.841036Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"读入后，我们可以做一些数据可视化操作，主要是验证我们读入的数据是否正确","metadata":{}},{"cell_type":"code","source":"image, label = next(iter(train_loader))\nprint(image.shape, label.shape)\nplt.imshow(image[0][0], cmap=\"gray\")\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-17T13:41:03.846765Z","iopub.execute_input":"2022-05-17T13:41:03.847170Z","iopub.status.idle":"2022-05-17T13:41:04.388263Z","shell.execute_reply.started":"2022-05-17T13:41:03.847109Z","shell.execute_reply":"2022-05-17T13:41:04.387272Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"torch.Size([256, 1, 28, 28]) torch.Size([256])\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f19e9d68290>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"**模型设计**  \n由于任务较为简单，这里我们手搭一个CNN，而不考虑当下各种模型的复杂结构  \n模型构建完成后，将模型放到GPU上用于训练  \n","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 32, 5),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2),\n            nn.Dropout(0.3),\n            nn.Conv2d(32, 64, 5),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2),\n            nn.Dropout(0.3)\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(64*4*4, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = x.view(-1, 64*4*4)\n        x = self.fc(x)\n        # x = nn.functional.normalize(x)\n        return x\n\nmodel = Net()\nmodel = model.cuda()\n# model = nn.DataParallel(model).cuda()   # 多卡训练时的写法，之后的课程中会进一步讲解","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:41:04.390245Z","iopub.execute_input":"2022-05-17T13:41:04.391069Z","iopub.status.idle":"2022-05-17T13:41:04.414586Z","shell.execute_reply.started":"2022-05-17T13:41:04.391022Z","shell.execute_reply":"2022-05-17T13:41:04.413558Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"**设定损失函数**  \n使用torch.nn模块自带的CrossEntropy损失  \nPyTorch会自动把整数型的label转为one-hot型，用于计算CE loss  \n这里需要确保label是从0开始的，同时模型不加softmax层（使用logits计算）,这也说明了PyTorch训练中各个部分不是独立的，需要通盘考虑","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n# criterion = nn.CrossEntropyLoss(weight=[1,1,1,1,3,1,1,1,1,1])","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:41:04.416661Z","iopub.execute_input":"2022-05-17T13:41:04.417309Z","iopub.status.idle":"2022-05-17T13:41:04.422610Z","shell.execute_reply.started":"2022-05-17T13:41:04.417246Z","shell.execute_reply":"2022-05-17T13:41:04.421413Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"?nn.CrossEntropyLoss # 这里方便看一下weighting等策略","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:41:04.424510Z","iopub.execute_input":"2022-05-17T13:41:04.425116Z","iopub.status.idle":"2022-05-17T13:41:04.436028Z","shell.execute_reply.started":"2022-05-17T13:41:04.425066Z","shell.execute_reply":"2022-05-17T13:41:04.434717Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Object `nn.CrossEntropyLoss # 这里方便看一下weighting等策略` not found.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**设定优化器**  \n这里我们使用Adam优化器  ","metadata":{}},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:41:04.438187Z","iopub.execute_input":"2022-05-17T13:41:04.438834Z","iopub.status.idle":"2022-05-17T13:41:04.445421Z","shell.execute_reply.started":"2022-05-17T13:41:04.438792Z","shell.execute_reply":"2022-05-17T13:41:04.444207Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"**训练和测试（验证）**  \n各自封装成函数，方便后续调用  \n关注两者的主要区别：  \n- 模型状态设置  \n- 是否需要初始化优化器\n- 是否需要将loss传回到网络\n- 是否需要每步更新optimizer  \n  \n此外，对于测试或验证过程，可以计算分类准确率","metadata":{}},{"cell_type":"code","source":"def train(epoch):\n    model.train()\n    train_loss = 0\n    for data, label in train_loader:\n        data, label = data.cuda(), label.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, label)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()*data.size(0)\n    train_loss = train_loss/len(train_loader.dataset)\n    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:41:04.447519Z","iopub.execute_input":"2022-05-17T13:41:04.448131Z","iopub.status.idle":"2022-05-17T13:41:04.458489Z","shell.execute_reply.started":"2022-05-17T13:41:04.448089Z","shell.execute_reply":"2022-05-17T13:41:04.457279Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def val(epoch):       \n    model.eval()\n    val_loss = 0\n    gt_labels = []\n    pred_labels = []\n    with torch.no_grad():\n        for data, label in test_loader:\n            data, label = data.cuda(), label.cuda()\n            output = model(data)\n            preds = torch.argmax(output, 1)\n            gt_labels.append(label.cpu().data.numpy())\n            pred_labels.append(preds.cpu().data.numpy())\n            loss = criterion(output, label)\n            val_loss += loss.item()*data.size(0)\n    val_loss = val_loss/len(test_loader.dataset)\n    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)\n    print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:41:04.460423Z","iopub.execute_input":"2022-05-17T13:41:04.461079Z","iopub.status.idle":"2022-05-17T13:41:04.474313Z","shell.execute_reply.started":"2022-05-17T13:41:04.461035Z","shell.execute_reply":"2022-05-17T13:41:04.473292Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, epochs+1):\n    train(epoch)\n    val(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:41:04.476198Z","iopub.execute_input":"2022-05-17T13:41:04.476711Z","iopub.status.idle":"2022-05-17T13:45:56.059388Z","shell.execute_reply.started":"2022-05-17T13:41:04.476671Z","shell.execute_reply":"2022-05-17T13:45:56.056773Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Epoch: 1 \tTraining Loss: 0.679150\nEpoch: 1 \tValidation Loss: 0.439492, Accuracy: 0.840200\nEpoch: 2 \tTraining Loss: 0.431484\nEpoch: 2 \tValidation Loss: 0.361335, Accuracy: 0.868900\nEpoch: 3 \tTraining Loss: 0.371326\nEpoch: 3 \tValidation Loss: 0.312176, Accuracy: 0.884100\nEpoch: 4 \tTraining Loss: 0.333142\nEpoch: 4 \tValidation Loss: 0.293982, Accuracy: 0.891100\nEpoch: 5 \tTraining Loss: 0.313300\nEpoch: 5 \tValidation Loss: 0.269924, Accuracy: 0.902700\nEpoch: 6 \tTraining Loss: 0.294425\nEpoch: 6 \tValidation Loss: 0.254612, Accuracy: 0.908000\nEpoch: 7 \tTraining Loss: 0.281989\nEpoch: 7 \tValidation Loss: 0.257299, Accuracy: 0.907700\nEpoch: 8 \tTraining Loss: 0.267962\nEpoch: 8 \tValidation Loss: 0.240243, Accuracy: 0.911600\nEpoch: 9 \tTraining Loss: 0.258821\nEpoch: 9 \tValidation Loss: 0.231982, Accuracy: 0.913500\nEpoch: 10 \tTraining Loss: 0.244142\nEpoch: 10 \tValidation Loss: 0.242404, Accuracy: 0.909400\nEpoch: 11 \tTraining Loss: 0.238906\nEpoch: 11 \tValidation Loss: 0.231034, Accuracy: 0.914100\nEpoch: 12 \tTraining Loss: 0.229381\nEpoch: 12 \tValidation Loss: 0.217238, Accuracy: 0.919900\nEpoch: 13 \tTraining Loss: 0.221999\nEpoch: 13 \tValidation Loss: 0.220666, Accuracy: 0.918400\nEpoch: 14 \tTraining Loss: 0.215038\nEpoch: 14 \tValidation Loss: 0.212959, Accuracy: 0.920200\nEpoch: 15 \tTraining Loss: 0.208892\nEpoch: 15 \tValidation Loss: 0.209004, Accuracy: 0.923300\nEpoch: 16 \tTraining Loss: 0.202349\nEpoch: 16 \tValidation Loss: 0.212455, Accuracy: 0.921300\nEpoch: 17 \tTraining Loss: 0.196926\nEpoch: 17 \tValidation Loss: 0.208251, Accuracy: 0.923300\nEpoch: 18 \tTraining Loss: 0.187776\nEpoch: 18 \tValidation Loss: 0.217086, Accuracy: 0.921300\nEpoch: 19 \tTraining Loss: 0.185715\nEpoch: 19 \tValidation Loss: 0.203405, Accuracy: 0.925600\nEpoch: 20 \tTraining Loss: 0.178926\nEpoch: 20 \tValidation Loss: 0.202856, Accuracy: 0.924400\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**模型保存**  \n训练完成后，可以使用torch.save保存模型参数或者整个模型，也可以在训练过程中保存模型  \n这部分会在后面的课程中详细介绍","metadata":{}},{"cell_type":"code","source":"save_path = \"./FahionModel.pkl\"\ntorch.save(model, save_path)","metadata":{"trusted":true},"execution_count":45,"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_33/2571602474.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    .pkl\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (2571602474.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}